import torch
from PIL import Image
import numpy as np
import json
from nuscenes.nuscenes import NuScenes ## pip install nuscenes-devkit
from torch.utils.data import Dataset
import os


class NuScenesDataset(Dataset):
	"""NuScenes dataset for 2d annotations."""

	def __init__(self, root_dir, annotation_path, nusc_version = 'v1.0-mini', transform=None, cfg = None):
		"""
		Args:
			root_dir (string): Path to the dataset.

			### This 2d annotations file is generated by running the following script
			https://github.com/nutonomy/nuscenes-devkit/blob/master/python-sdk/nuscenes/scripts/export_2d_annotations_as_json.py
			
			## This script to be run as below
			python export_2d_annotations_as_json.py --dataroot /home/Nuscenes/ --filename /home/Nuscenes/2d_image_annotations.json --version v1.0-mini
			annotation_dir: json file containing 2d annotations
			
			nusc_version: version of the dataset

			transform (callable, optional): Optional transform to be applied
				on a sample.
		"""
		self.root_dir = root_dir
		self.annotation_path = annotation_path
		self.nusc_version = nusc_version

		## load annotations and process it to be used by __getitem__(), c'mon
		nusc = NuScenes(version=self.nusc_version, dataroot=self.root_dir, verbose=True) 
		self.cat_ids = {}

		## Getting all categories
		for ind in range(len(nusc.category)): 
			self.cat_ids[nusc.category[ind]['name']] = ind

		## 
		with open(annotation_path) as json_file: 
			data = json.load(json_file)

		annotation_dict = {}

		for i in range(len(data)):
			
			bbox = data[i]['bbox_corners']
			category_name = data[i]['category_name']
			cat_id = self.cat_ids[category_name] 
			file_name = data[i]['filename']
			ann_dict = {'bbox':[bbox], 'category_name':category_name, 'cat_id':cat_id}

			## Meaning this image has already been seen!! :D :D :D :D :D 
			if file_name not in annotation_dict:
				annotation_dict[file_name] = []
				annotation_dict[file_name].append(ann_dict)

			## We have already seen the image
			else:
				annotation_dict[file_name].append(ann_dict)

		## Image transform
		self.transform = transform
		
		## has all the annotations 
		'''
		It's a dictionary, with keys() as relative image_paths.
		Each key leads to a list of annotations, corresponding to that particular image
		'''
		self.annotation_dict = annotation_dict
		self.cfg = cfg
	

	def __len__(self):
		return len(self.annotation_dict.keys())

	def __getitem__(self, idx):
		if torch.is_tensor(idx):
			idx = idx.tolist()

		rel_image_path = list(self.annotation_dict.keys())[idx]
		img_path = os.path.join(self.root_dir,
								rel_image_path)

		## loading the image
		img = Image.open(img_path).convert('RGB')
		width, height = img.size
		new_width, new_height = int(width/self.cfg.TRAIN.NUSCENES_IMAGE_RESIZE_FACTOR), int(height/self.cfg.TRAIN.NUSCENES_IMAGE_RESIZE_FACTOR)
		img = img.resize((new_width, new_height))
		target = self.annotation_dict[rel_image_path]

		## transform the image
		if self.transform:
			img = self.transform(img)


		return img, target, img_path

# A collate function to enable loading the Nuscenes label in batch
def nuscenes_collate_fn(batch):

	## let's get the images stacked up
	data = torch.stack([item[0] for item in batch])

	## getting the target in a list
	target = [item[1] for item in batch]

	## Getting paths in list
	paths = [item[2] for item in batch]
	# target = [item[1] for item in batch]
	# target = torch.LongTensor(target)
	return [data, target, paths]